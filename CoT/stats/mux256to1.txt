Traceback (most recent call last):
  File "/home/aboba/Work/Ramesh/Bench/llm_hardware_bench/./response.py", line 186, in <module>
    main()
  File "/home/aboba/Work/Ramesh/Bench/llm_hardware_bench/./response.py", line 181, in main
    get_response(prompt, module, model, outdir, logfile, prompt_strategy)
  File "/home/aboba/Work/Ramesh/Bench/llm_hardware_bench/./response.py", line 93, in get_response
    response = generate_verilog(conv, model_type)
  File "/home/aboba/Work/Ramesh/Bench/llm_hardware_bench/./response.py", line 73, in generate_verilog
    return(model.generate(conv))
  File "/home/aboba/Work/Ramesh/Bench/llm_hardware_bench/languagemodels.py", line 58, in generate
    response = openai.ChatCompletion.create(
  File "/home/aboba/.local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py", line 25, in create
    return super().create(*args, **kwargs)
  File "/home/aboba/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py", line 153, in create
    response, _, api_key = requestor.request(
  File "/home/aboba/.local/lib/python3.10/site-packages/openai/api_requestor.py", line 298, in request
    resp, got_stream = self._interpret_response(result, stream)
  File "/home/aboba/.local/lib/python3.10/site-packages/openai/api_requestor.py", line 700, in _interpret_response
    self._interpret_response_line(
  File "/home/aboba/.local/lib/python3.10/site-packages/openai/api_requestor.py", line 765, in _interpret_response_line
    raise self.handle_error_response(
openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.
